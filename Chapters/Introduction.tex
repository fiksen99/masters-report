
\chapter{Introduction} % Main chapter title

\label{Introduction} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

%\lhead{Chapter 1. \emph{Introduction}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

\section{Motivation}

Students of Computer Science across the world are intially brought into the field
with simple exercises, designed to educate and test their ability on concepts
fundamental to a good software engineer. With the huge volume of code submitted,
there is a wealthy resource of patterns and information that can be extracted
from their source code. Our aim is to look into the code structure and find
a measure of how similar or different the students' code is from one another.
With this data, we are in a position to analyse the coding habits of the students,
providing insight into their work ethic, their performance and understand compared
to their peers and potentially much more.

The current submission system for students provides a gitlab
environment to submit their codebase. However, current utilisation of gitlab 
data is minimal -- primarily it provides a
convenient form of code submission for the students, with no analysis of the 
data to gather more in depth information on the students' performance.
The gitlab repositories provide us with the potential to both aid markers
in delivering consistent and correct grades and feedback, as well as allowing
the students to analyse their own work in comparison with others, so that they
can reflect on their own implementation. It is the underutilisation of this
data that we aim to overcome.

\section{Objectives}
This project has a number of aims to achieve, primarily aiming to develop a 
tool, giving interesting analysis of student coding patterns. 

The development of this tool however, brings about other goals that we'd like to
achieve:
\begin{itemize}

\item Modification of plagiarism detection techniques to give an accurate value
of similarity of student code. Current research predominantely returns a binary
(or occasionaly ternary) `yes', `no' (or `maybe') value, we wish to give a much
finer grained answer.

\item Analysis of similarity measures as to which provides the most accurate
and useful information.

\item Interesting statistical analysis and data visualisation of the data -- 
we'd like to be able to cluster similar code and see how these clusters change
over the course of projects; how the marks awarded vary within a cluster, and
other interesting insights. 

\item Presentation of data in a way which provides utility for current markers
-- group feedback to be given on simliarly structured code etc.

\end{itemize}

\section{Contributions}

The project shares it's focus between a software engineering approach and statistical
analysis; as such, the contributions are varied:

\begin{itemize}

\item An Eclipse plugin to compute similarity between projects in the workspace.
This plugin returns values only on chosen files, ignoring the
similarity of selected files as given by the user (e.g. any library files students
aren't expected to change). It outputs to text file the data in various forms
for easy analysis.

\item An extension to the plugin, allowing comparison of individual files,
with the most similar methods being highlighted in a diff window.

\item An implementation of a similarity analysis algorithm integrated in the
plugin

\item A bash script to generate eclipse projects and thus valid classpaths etc.
for projects in all subdirectories given a group of folders containing bare git
repositories. Also the ability to clean these folders back to just the git
repository

\item Settings to be passed into the python library Orange to perform clustering
and data visualisation on the outputted data.

\item Statistical analysis of the clusters.

\end{itemize}
